[
  {
    "objectID": "conf-register.html",
    "href": "conf-register.html",
    "title": "Registration",
    "section": "",
    "text": "We are currently planning on organizing a 2023 Big Team Science Conference in late 2023. Once registration is open, we will add information here."
  },
  {
    "objectID": "papers.html",
    "href": "papers.html",
    "title": "Papers",
    "section": "",
    "text": "The Psychological Science Accelerator: Advancing psychology through a distributed collaborative network\n        Concerns about the veracity of psychological research have been growing.\n        DOI: 10.1177/2515245918797607\n        Categories: meta-science\n    \n  \n\n\nNo matching items"
  },
  {
    "objectID": "join.html",
    "href": "join.html",
    "title": "Join the PSA",
    "section": "",
    "text": "To join the PSA, you should:\n\nCreate an account on this webpage.\nYou will receive an invitation to join the PSA Membership Website (Canvas). Please check your spam email!\nYou will receive an invitation to join the PSA Membership “course”, which is where you can agree to the code of conduct and fill in your profile information. We use this information to match you with opportunities in the PSA.\nAccounts are usually created within a few days by the web admin.\nAll projects use the membership website to send messages, track information, and keep you up to date."
  },
  {
    "objectID": "join.html#new-member-account-registration",
    "href": "join.html#new-member-account-registration",
    "title": "Join the PSA",
    "section": "",
    "text": "To join the PSA, you should:\n\nCreate an account on this webpage.\nYou will receive an invitation to join the PSA Membership Website (Canvas). Please check your spam email!\nYou will receive an invitation to join the PSA Membership “course”, which is where you can agree to the code of conduct and fill in your profile information. We use this information to match you with opportunities in the PSA.\nAccounts are usually created within a few days by the web admin.\nAll projects use the membership website to send messages, track information, and keep you up to date."
  },
  {
    "objectID": "join.html#membership",
    "href": "join.html#membership",
    "title": "Join the PSA",
    "section": "Membership",
    "text": "Membership\n\nMembership in the Psychological Science Accelerator\nThis policy document details how to become a member of the PSA, how to maintain active membership in the PSA, the responsibilities of active PSA members, and the rights of active PSA members. Accurate active membership information helps us estimate PSA capacity for future projects.\nBecoming a Member of the PSA:\n\nRead and agree to abide by the code of conduct.\nRead and agree to support the mission and core principles of the PSA when working on projects supported by the PSA.\nProvide information for the PSA roster, and indicate what information we can share publicly.\nYou must have a current email, as we delete users when their email bounces!\n\nAll three of the above items are gathered on the membership website.\n\n\nMaintaining Membership in the PSA. All PSA members must:\n\nAbide by the code of conduct.\nReport misconduct or violations of the code of conduct (via anonymous online survey if preferred).\nContribute to some aspect of the PSA at least once per year. One can join and gain membership immediately, and then have one year to become involved to maintain membership. Here is a non-exhaustive list of examples of contributions (we will err on the side of inclusion, rather than exclusion, when evaluating contributions that maintain active membership):\n\nCollect data for a PSA study\nMake non-data-collection contributions to a PSA study\nServe on a PSA committee\nReview a PSA study submission (peer reviewer)\nRate a PSA study submission (full network survey)\nTranslate materials for a PSA study\nProvide feedback on a PSA study before submission\nDraft, edit, or provide feedback on a PSA policy document\nVote in elections, study selection, or other requests for feedback\nFill in your online profile, keeping your email up to date\n\n\nMembers who have not engaged in PSA activities for a year will be marked as passive members. These members will still receive PSA communications (newsletters and emails) but will not have voting or nominating rights while they are passive members (see below). Passive members who re-engage with the PSA by contributing in any of the-above listed ways will be once again marked as active members for one year following their most recent contribution.\n\n\nRights of PSA members. All PSA members may:\n\nIndicate their willingness to contribute to, and earn authorship on, PSA projects.\nProvide feedback on all projects at these stages: study selection, prior to protocol and analysis plan being finalized, prior to any stage of publication submission (initial submission, revisions, etc.).\nJoin and earn authorship on projects if warranted by their contributions. Note that there may be scenarios when joining a specific study cannot be guaranteed for logistical reasons.\nVote in elections for the Director and Associate Directors of the PSA.\nProvide feedback on all policy documents and vote to ratify or reject possible PSA policies.\nProvide anonymous feedback on all PSA procedures and workflows (via online survey).\nNominate a PSA member, or oneself, for Election or Appointment to any PSA leadership position.\nAnyone can ask to be removed as a member at any time by emailing psysciaccelerator@gmail.com.\n\n\n\nCompulsory Membership:\nAll contributors to PSA studies must become members during their contribution to the project. This is to ensure that all researchers engaging with the PSA have read and agree to abide by our Code of Conduct."
  },
  {
    "objectID": "projects/CR003/index.html",
    "href": "projects/CR003/index.html",
    "title": "PSA-CR 003: Self Determination",
    "section": "",
    "text": "Legate, N., Nguyen, T. T., Weinstein, N., Moller, A. C., Legault, L., Adamkovic, M., … Primbs, M. (2021, May 30). A Global Experiment on Motivating Social Distancing during the COVID-19 Pandemic. https://doi.org/10.1073/pnas.2111091119"
  },
  {
    "objectID": "projects/007/index.html",
    "href": "projects/007/index.html",
    "title": "PSA007: SPAM-L",
    "section": "",
    "text": "For more information about this project, please contact Erin Buchanan at 007spaml@gmail.com."
  },
  {
    "objectID": "projects/007/index.html#contact",
    "href": "projects/007/index.html#contact",
    "title": "PSA007: SPAM-L",
    "section": "",
    "text": "For more information about this project, please contact Erin Buchanan at 007spaml@gmail.com."
  },
  {
    "objectID": "projects/008/index.html",
    "href": "projects/008/index.html",
    "title": "PSA008: Minimal Groups",
    "section": "",
    "text": "For more information about this project, please contact Kathleen Schmidt at kathleenschmidt1@gmail.com."
  },
  {
    "objectID": "projects/008/index.html#contact",
    "href": "projects/008/index.html#contact",
    "title": "PSA008: Minimal Groups",
    "section": "",
    "text": "For more information about this project, please contact Kathleen Schmidt at kathleenschmidt1@gmail.com."
  },
  {
    "objectID": "projects/001/index.html",
    "href": "projects/001/index.html",
    "title": "PSA001: Face Perception",
    "section": "",
    "text": "Jones, B.C., DeBruine, L.M., Flake, J.K. et al. To which world regions does the valence–dominance model of social perception apply?. Nat Hum Behav 5, 159–169 (2021). https://doi.org/10.1038/s41562-020-01007-2\n\nNews\n\nScience: A new ‘accelerator’ aims to bring big science to psychology (2017-11-08)\nBuzzfeed: Hundreds Of Researchers Are Trying To Replicate High-Profile Psychology Studies (2018-04-03)\nIdeastream: Putting a New Face on Psychological Research (2020-01-13)"
  },
  {
    "objectID": "projects/006/index.html",
    "href": "projects/006/index.html",
    "title": "PSA006: Trolley Problem",
    "section": "",
    "text": "Bago, B., Kovacs, M., Protzko, J. et al. Situational factors shape moral judgements in the trolley dilemma in Eastern, Southern and Western countries in a culturally diverse sample. Nat Hum Behav 6, 880–895 (2022). https://doi.org/10.1038/s41562-022-01319-5"
  },
  {
    "objectID": "projects/CR001/index.html",
    "href": "projects/CR001/index.html",
    "title": "PSA-CR 001: Loss Gain",
    "section": "",
    "text": "Dorison, C.A., Lerner, J.S., Heller, B.H. et al. (2022) In COVID-19 Health Messaging, Loss Framing Increases Anxiety with Little-to-No Concomitant Benefits: Experimental Evidence from 84 Countries. Affective Science 3, 577–602. https://doi.org/10.1007/s42761-022-00128-3"
  },
  {
    "objectID": "projects/003/index.html",
    "href": "projects/003/index.html",
    "title": "PSA003: Gendered Prejudice",
    "section": "",
    "text": "For more information about this project, please contact Curtis Phills at [curtis.phills@gmail.com] (mailto:curtis.phills@gmail.com) or Jeremy Miller at [millerj@willamette.edu] (mailto:millerj@willamette.edu)."
  },
  {
    "objectID": "projects/003/index.html#contact",
    "href": "projects/003/index.html#contact",
    "title": "PSA003: Gendered Prejudice",
    "section": "",
    "text": "For more information about this project, please contact Curtis Phills at [curtis.phills@gmail.com] (mailto:curtis.phills@gmail.com) or Jeremy Miller at [millerj@willamette.edu] (mailto:millerj@willamette.edu)."
  },
  {
    "objectID": "projects/004/index.html",
    "href": "projects/004/index.html",
    "title": "PSA004: True Belief",
    "section": "",
    "text": "For more information about this project, please contact Jordan Wagge at jwagge@gmail.com."
  },
  {
    "objectID": "projects/004/index.html#contact",
    "href": "projects/004/index.html#contact",
    "title": "PSA004: True Belief",
    "section": "",
    "text": "For more information about this project, please contact Jordan Wagge at jwagge@gmail.com."
  },
  {
    "objectID": "projects/005/index.html",
    "href": "projects/005/index.html",
    "title": "PSA005: Stereotype Threat",
    "section": "",
    "text": "For more information about this project, please contact Patrick Forscher at psa005stero@gmail.com."
  },
  {
    "objectID": "projects/005/index.html#contact",
    "href": "projects/005/index.html#contact",
    "title": "PSA005: Stereotype Threat",
    "section": "",
    "text": "For more information about this project, please contact Patrick Forscher at psa005stero@gmail.com."
  },
  {
    "objectID": "projects/002/index.html",
    "href": "projects/002/index.html",
    "title": "PSA002: Object Orientation",
    "section": "",
    "text": "For more information about this project, please contact Sau-Chin Chen at pmsp96@gmail.com or Jeremy Miller at [millerj@willamette.edu] (mailto:millerj@willamette.edu)."
  },
  {
    "objectID": "projects/002/index.html#contact",
    "href": "projects/002/index.html#contact",
    "title": "PSA002: Object Orientation",
    "section": "",
    "text": "For more information about this project, please contact Sau-Chin Chen at pmsp96@gmail.com or Jeremy Miller at [millerj@willamette.edu] (mailto:millerj@willamette.edu)."
  },
  {
    "objectID": "news.html",
    "href": "news.html",
    "title": "News",
    "section": "",
    "text": "Second Special Call for Studies – Studying Generalizability with Global Samples\n\n\n\n\n\nThe Psychological Science Accelerator (PSA), supported by the John Templeton Foundation (JTF), welcomes study proposals to test the generalizability of phenomena related to JTF strategic priorities with large, global samples. Full Proposals due by May 15, 2023.\n\n\n\n\n\n\nDec 6, 2022\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Projects",
    "section": "",
    "text": "PSA001: Face Perception\n      \n        paper\n        preprint\n        resources\n      \n      Over the past 10 years, Oosterhof and Todorov’s valence–dominance model has emerged as the most prominent account of how people evaluate faces on social dimensions. In this model, two dimensions (valence and dominance) underpin social judgements of faces. Because this model has primarily been developed and tested in Western regions, it is unclear whether these findings apply to other regions. We addressed this question by replicating Oosterhof and Todorov’s methodology across 11 world regions, 41 countries and 11,570 participants. When we used Oosterhof and Todorov’s original analysis strategy, the valence–dominance model generalized across regions. When we used an alternative methodology to allow for correlated dimensions, we observed much less generalization. Collectively, these results suggest that, while the valence–dominance model generalizes very well across regions when dimensions are forced to be orthogonal, regional differences are revealed when we use different extraction methods and correlate and rotate the dimension reduction solution.\n\n    \n  \n  \n    \n      \n      \n      \n    \n    \n    \n      PSA002: Object Orientation\n      \n        preprint\n      \n      Mental simulation theories of language comprehension propose that people automatically create mental representations of real objects. Evidence from sentence-picture verification tasks has shown that people mentally represent various visual properties such as shape, color, and size. However, the evidence for mental simulations of object orientation is limited. We report a study that investigates the match advantage of object orientation across speakers of different languages. This multi-laboratory project aims to achieve two objectives. First, we examine the replicability of the match advantage of object orientation across multiple languages and laboratories. Second, we will use a mental rotation task to measure participants’ mental imagery after the sentence-picture verification task. The relationship between the participants’ performance of the two tasks will provide a cross-linguistic examination of perceptual simulation processes. With the (broad) evaluation of individual mental imagery ability and potential linguistic moderators, we expect a robust estimation of match advantage of object orientation.\n\n    \n  \n  \n    \n      \n      \n      \n    \n    \n      PSA003: Gendered Prejudice\n      When asked to imagine a person, people tend to think of a man (Hamilton, 1991). The same is true for some social groups as well–when asked to imagine a Black or White person, people tend to imagine a Black or White man (Schug, Alt, & Klauer, 2015). One reason for this is androcentrism: the belief that men are the default and women are the exception or “other” (Bailey, LaFrance, & Dovidio, 2018; Bem, 1993; Smith & Zarate, 1992).The present research will describe the gendered nature of prejudice for seven social categories (i.e., Black people, East Asian people, White people, police, politicians, and criminals). We hypothesized that, if prejudice occurs for the group, it is more strongly related to prejudice toward the men of that social category than toward the women of that category. This study was conducted across several laboratories and languages and was paired with PSA 002 for data collection.\n\n    \n  \n  \n    \n      \n      \n      \n    \n    \n    \n      PSA004: True Belief\n      \n        preprint\n      \n      According to the Justified True Belief account of knowledge (JTB), a person can only truly know something if they have a belief that is both justified and true (i.e., knowledge is justified true belief). This account was challenged by Gettier (1963), who argued that JTB does not explain knowledge attributions in certain situations, later called Gettier-type cases, wherein a protagonist is justified in believing something to be true but their belief was only correct due to luck. Lay people may not attribute knowledge to protagonists with justified but only luckily true beliefs. While some research has found evidence for these so-called Gettier intuitions (e.g., Machery et al., 2017a), Turri et al. (2015) found that participants attributed knowledge in Gettier-type cases at rates similar to cases of justified true belief. In a large-scale, cross-cultural conceptual replication of Turri and colleagues’ (2015) Experiment 1 (N = 4724), we failed to replicate this null result using a within-subjects design and three vignettes across 19 geopolitical regions. Instead, participants demonstrated Gettier intuitions; they were 1.86 times more likely to attribute knowledge to protagonists in standard cases of justified true belief than to protagonists in Gettier-type cases. These results suggest that Gettier intuitions may be common across different scenarios and cultural contexts. When assessing the knowledge of others, lay people may rely on a shared set of epistemic intuitions (i.e., a core folk epistemology) that requires more than simply justification, belief, and truth. However, the size of the Gettier intuition effect did vary by vignette, and the Turri et al. (2015) vignette produced the smallest effect. Thus, epistemic intuitions may also depend on contextual factors unrelated to the criteria of knowledge, such as the characteristics of the protagonist being evaluated.\n\n    \n  \n  \n    \n      \n      \n      \n    \n    \n    \n      PSA005: Stereotype Threat\n      \n        preprint\n      \n      According to stereotype threat theory, the possibility of confirming a negative group stereotype evokes feelings of threat, leading people to underperform in domains where they are stereotyped as lacking ability. This theory has immense theoretical and practical implications. However, many studies supporting it include small samples and varying operational definitions of “stereotype threat”. We address the first challenge by leveraging a network of psychology labs to recruit a large Black student sample (*N~anticipated~* = 2700) from multiple US sites (*N~anticipated~* = 27). We address the second challenge by identifying three threat-increasing and three threat-decreasing procedures that could plausibly affect performance and use an adaptive Bayesian design to determine which operationalization yields the strongest evidence for underperformance. This project should advance our knowledge of a scientifically and socially important topic: the conditions under which stereotype threat affects performance among current Black students in the United States.\n\n    \n  \n  \n    \n      \n      \n      \n    \n    \n    \n      PSA006: Trolley Problem\n      \n        paper\n        preprint\n        RR stage 1\n        resources\n        OSF\n      \n      The study of moral judgements often centres on moral dilemmas in which options consistent with deontological perspectives (that is, emphasizing rules, individual rights and duties) are in conflict with options consistent with utilitarian judgements (that is, following the greater good based on consequences). Greene et al. (2009) showed that psychological and situational factors (for example, the intent of the agent or the presence of physical contact between the agent and the victim) can play an important role in moral dilemma judgements (for example, the trolley problem). Our knowledge is limited concerning both the universality of these effects outside the United States and the impact of culture on the situational and psychological factors affecting moral judgements. Thus, we empirically tested the universality of the effects of intent and personal force on moral dilemma judgements by replicating the experiments of Greene et al. in 45 countries from all inhabited continents. We found that personal force and its interaction with intention exert influence on moral judgements in the US and Western cultural clusters, replicating and expanding the original findings. Moreover, the personal force effect was present in all cultural clusters, suggesting it is culturally universal. The evidence for the cultural universality of the interaction effect was inconclusive in the Eastern and Southern cultural clusters (depending on exclusion criteria). We found no strong association between collectivism/individualism and moral dilemma judgements.\n\n    \n  \n  \n    \n      \n      \n      \n    \n    \n    \n      PSA007: SPAM-L\n      \n        preprint\n      \n      Semantic priming has been studied for nearly 50 years across various experimental manipulations and theoretical frameworks. These studies provide insight into the cognitive underpinnings of semantic representations in both healthy and clinical populations; however, they have suffered from several issues including generally low sample sizes and a lack of diversity in linguistic implementations. Here, we will test the size and the variability of the semantic priming effect across ten languages by creating a large database of semantic priming values, based on an adaptive sampling procedure. Differences in response latencies between related word-pair conditions and unrelated word-pair conditions (i.e., difference score confidence interval is greater than zero) will allow quantifying evidence for semantic priming, whereas improvements in model fit with the addition of a random intercept for language will provide support for variability in semantic priming across languages.\n\n    \n  \n  \n    \n      \n      \n      \n    \n    \n      PSA008: Minimal Groups\n      Biases in favor of culturally prevalent social ingroups are ubiquitous, but random assignment to meaningless experimentally created social groups is also sufficient to create ingroup biases (i.e., the minimal group effect; MGE). Thus, the extent to which ingroup bias arises from specific social contexts versus more general psychological tendencies remains unclear. This registered report focuses on three questions. First, how culturally prevalent is the MGE? Second, how do critical cultural and individual factors moderate its strength? Third, does the MGE meaningfully relate to culturally salient real-world ingroup biases? Here we compare the MGE to bias in favor of a family member (i.e., first cousin) and a national ingroup member. We propose to recruit a sample of &gt; 200 participants in each of &gt; 50 nations to examine these questions and advance our understanding of the psychological foundations and cultural prevalence of ingroup bias.\n\n    \n  \n  \n    \n      \n      \n      \n    \n    \n    \n      PSA-CR 001: Loss Gain\n      \n        paper\n        preprint\n      \n      The COVID-19 pandemic presents a critical need to identify best practices for communicating health information to the global public. It also provides an opportunity to test theories about risk communication. As part of a larger Psychological Science Accelerator COVID-19 Rapid Project, a global consortium of researchers will experimentally test competing hypotheses regarding the effects of framing messages in terms of losses versus gains. We will examine effects on three primary outcomes: intentions to adhere to policies designed to prevent the spread of COVID-19, opinions about such policies, and the likelihood that participants seek additional policy information. Whereas research on negativity bias and loss aversion predicts that loss-framing will have greater impact, research on encouraging the adoption of protective health behaviour suggests the opposite (i.e., gain-framing will be more persuasive). We will also assess effects on experienced anxiety. Given the potentially low cost and the scalable nature of framing interventions, results could be valuable to health organizations, policymakers, and news sources globally.\n\n    \n  \n  \n    \n      \n      \n      \n    \n    \n    \n      PSA-CR 002: Cognitive Reappraisal\n      \n        paper\n      \n      The COVID-19 pandemic has increased negative emotions and decreased positive emotions globally. Left unchecked, these emotional changes might have a wide array of adverse impacts. To reduce negative emotions and increase positive emotions, we tested the effectiveness of reappraisal, an emotion-regulation strategy that modifies how one thinks about a situation. Participants from 87 countries and regions (*n* = 21,644) were randomly assigned to one of two brief reappraisal interventions (reconstrual or repurposing) or one of two control conditions (active or passive). Results revealed that both reappraisal interventions (vesus both control conditions) consistently reduced negative emotions and increased positive emotions across different measures. Reconstrual and repurposing interventions had similar effects. Importantly, planned exploratory analyses indicated that reappraisal interventions did not reduce intentions to practice preventive health behaviours. The findings demonstrate the viability of creating scalable, low-cost interventions for use around the world.\n\n    \n  \n  \n    \n      \n      \n      \n    \n    \n    \n      PSA-CR 003: Self Determination\n      \n        paper\n        preprint\n        resources\n      \n      In order to slow the transmission of COVID-19, governments around the world are asking their citizens to participate in social distancing, that is, to stay at home as much as possible. In most countries, individuals have some choice over whether or not they follow recommendations for social distancing. Thus, understanding how to best motivate social distancing has become a critical public health priority. This study tests, in a confirmatory manner, whether self-determination theory-guided message framing impacts people’s motivation to participate in social distancing. Specifically, we expect autonomy-supportive messages that help people understand the value of behavior change to a) increase ‘buy in’, or autonomous motivation, for social distancing, b) lower feelings of defiance to follow recommendations around social distancing, and c) increase feelings of self-efficacy to participate in social distancing, relative to neutral and controlling messages. Further, we expect controlling messages that pressure people to change using shame, guilt, and threats, may backfire and a) decrease ‘buy in’ for social distancing and b) increase defiance, relative to the control condition. Exploratory tests will examine whether the effects of message framing on motivation and defiance extend to behavioral intentions and long-term commitment. This work has direct relevance for how public officials, health professionals, journalists, and others can communicate about solving this and future public health crises in ways that motivate people more effectively.\n\n    \n  \n  \n    \n      \n      \n      \n    \n    \n      AF001: Gratitude Project\n      To date, gratitude intervention research has mostly relied on WEIRD samples (i.e., people from Western, Educated, Industrialized, Rich, and Democratic societies). This has severely limited our understanding of both the function and potential benefits of gratitude. With funding from the John Templeton Foundation and in collaboration with the Psychological Science Accelerator consortium, we are seeking potential collaborators for a cross-cultural (~50 countries) examination of online, 30-minute, single-session gratitude interventions on subjective well-being. This will include both (1) standardized gratitude interventions traditionally developed and validated in WEIRD samples, and (2) localized (e.g., culturally tailored) gratitude interventions that collaborators might design if they so choose.\n\n    \n  \n  \n    \n      \n      \n      \n    \n    \n    \n      AF002: Preference Matching\n      Ideal partner preferences (i.e., ratings of the desirability of attributes like attractiveness or intelligence) are the source of numerous foundational findings in the interdisciplinary literature on human mating. Recently, research on the predictive validity of ideal partner preference-matching (i.e., do people positively evaluate partners who match versus mismatch their ideals?) has become mired in several problems. For one, articles exhibit discrepant analytic and reporting practices. Furthermore, different findings emerge across laboratories worldwide, perhaps because they sample different relationship contexts and/or populations. The current project—partnered with the Psychological Science Accelerator—can bring clarity to this literature. This registered report uses a highly powered design across multiple world regions to calculate preference-matching effect sizes and variability estimates for all relevant analytic tests. It also examines effects in different relationship contexts and subsamples (e.g., attraction, established relationships, recently formed relationships).\n\n    \n  \n\n\nNo matching items"
  },
  {
    "objectID": "newsletter.html",
    "href": "newsletter.html",
    "title": "Newsletter",
    "section": "",
    "text": "Want to receive regular updates about the PSA? Sign up for our monthly newsletter.\nIf you missed a past newsletter, fret not! Copies of all our past newsletters can be found here."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Psychological Science Accelerator",
    "section": "",
    "text": "The Psychological Science Accelerator (PSA) is a globally distributed network of researchers (2468 researchers from 73 countries) that pool intellectual and material resources to accelerate the accumulation of rigorous knowledge in psychological science.\nWe believe that many of the world’s biggest challenges cannot be addressed by a single researcher or small team. We thus seek to leverage big team science to address big questions rooted in theory and/or real-world problems. For example, of the 12+ projects in our study portfolio, we have:\n\nTested whether COVID-19-related cognitive framing manipulations impact emotions, behaviors, attitudes, and well-being around the world.\nExamined cultural and situations forces that shape moral dilemma judgments.\nExamined the extent to which stereotype threat impacts academic performance among African American college students [ongoing].\n\n\nRecent News\n\n\n\n\n  \n\n\n\n\nSecond Special Call for Studies – Studying Generalizability with Global Samples\n\n\n\n\n\nThe Psychological Science Accelerator (PSA), supported by the John Templeton Foundation (JTF), welcomes study proposals to test the generalizability of phenomena related to JTF strategic priorities with large, global samples. Full Proposals due by May 15, 2023.\n\n\n\n\n\n\n2022-12-06\n\n\n\n\n\n\nNo matching items\n\n\nOlder news…"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "The Psychological Science Accelerator (PSA) is a globally distributed network of researchers (2468 researchers from 73 countries) that pool intellectual and material resources to accelerate the accumulation of rigorous knowledge in psychological science. Below is some information about how we got started, our guiding principles, notable accomplishments, and future directions.\n\nBeginnings\nThe PSA began in August 2017 with a blog post titled “Building a CERN for Psychological Science,” in which one of the founders, Chris Chartier, called on multiple research labs to join together to create a large-scale research consortium. By virtue of its membership across multiple countries, it was argued that a large enough consortium could recruit larger and more diverse samples of research participants than would be possible in only one research lab. The post was shared widely, and 100 labs signed up for the consortium one month after the post went live. In the early days of the project, the ever-expanding membership selected the name “The Psychological Science Accelerator” for the consortium, established sustainable governance, and drafted the consortium’s guiding principles, which were later published in Advances in Methods and Practices in Psychological Science.\n\n\nCore Principles\nThe founding members of the PSA established the following core principles:\n\nDiversity and Inclusion: Endeavor towards diversity and inclusion in every aspect of the PSA’s functioning. This includes cultural and geographic diversity among participants and researchers conducting PSA-supported projects, as well as a diversity of research topics.\nDecentralized Authority: Have policies and procedures set by committees in conjunction with the PSA community at large. Have members collectively guide the direction of the PSA through the policies they vote for and the projects they support.\nTransparency: Mandate transparent practices in policies, procedures, and supported projects. For example, in confirmatory PSA projects, hypotheses, methods, and analysis plans should be specified and documented a-priori. Exploratory projects and analyses should be explicitly identified as so. Data, code, materials, and preprints of empirical results are required to be made openly available to the public.\nRigor: Enable, support, or require relatively large sampling plans, expert reviews of study rationale, and vetting of methods by members with expertise in measurement and quantitative analysis.\nOpenness to criticism: Integrate critical assessment into all policies and research products. Require extensive review of all projects and regularly solicit external feedback on the organization as a whole.\n\n\n\nKey Accomplishments\nBrought together a large researcher base. The PSA has demonstrated that there is wide-ranging support for big team science. As of 2023, 2468 researchers from 73 countries have joined the network. Often on a volunteer basis, these researchers contribute to the PSA in several ways, including: collecting data, serving on committees, donating funds, conducting novel methodological and meta-scientific research, supporting the management of projects and data releases, devising analysis plans, and reviewing submissions for future PSA projects.\nEstablished sustainable governance. As of December 2020, the PSA is fiscally sponsored by the Open Collective Foundation and led by a Director, four Associate Directors, an ever-shifting number of committees led by 1-2 Assistant Directors, and a grassroots network of contributors. Committees regularly meet to establish workflows, develop policies, and provide guidance to PSA projects.\nSelected and initiated over a dozen large-scale projects. The PSA currently has over a dozen large-scale projects. See of projects page (link) for more information.\nReceived recognition from the scientific community. In 2019, the PSA was recognized through the Society for the Improvement of Psychological Science’s Leadership Award. In 2021, the PSA was recognized through the Society for Personality and Social Psychology Service to the Field Award. The PSA has also received positive coverage from several popular press outlets, including Science Magazine, FiveThirtyEight, and Buzzfeed.\n\n\nCurrent Aims\nBetween 2022-2025, the PSA is primarily pursuing 6 aims. For more information, see our 2022-2025 Vision Plan.\n\nAddress the “generalizability crisis” as it applies to methodology, measurement, sampling, and data analysis\nImprove psychological science through meta-science research\nCreate opportunities for PSA members to initiate and collaborate on “affiliated” projects\nBuild infrastructure for large-scale collaboration networks\nImprove the diversity of psychological science\nEstablish long-term organizational and financial sustainability"
  },
  {
    "objectID": "contacts.html",
    "href": "contacts.html",
    "title": "Contact Us",
    "section": "",
    "text": "Want to chat? Send us an email or direct message on Twitter."
  },
  {
    "objectID": "core-principles.html",
    "href": "core-principles.html",
    "title": "Core Principles",
    "section": "",
    "text": "Diversity and inclusion\nWe endeavor towards diversity and inclusion in every aspect of the PSA’s functioning. This includes cultural and geographic diversity among participants and researchers conducting PSA-supported projects, as well as a diversity of research topics.\n\n\nDecentralized authority\nPSA policies and procedures are set by committees in conjunction with the PSA community at large. Members collectively guide the direction of the PSA through the policies they vote for and the projects they support.\n\n\nTransparency\nThe PSA mandates transparent practices in its own policies and procedures, as well as in the projects it supports. All PSA projects require pre-registration of the research: When it is confirmatory, a pre-registration of hypotheses, methods, and analysis plans (e.g., Van’t Veer & Giner-Sorolla, 2016), and when it is exploratory, an explicit statement saying so. In addition, open data, open code, open materials, and depositing an open- access preprint report of the empirical results are required.\n\n\nRigor\nThe PSA currently enables, supports, or requires appropriately large samples (Cohen, 1992; Ioannidis, 2005), expert review of the theoretical rationale (Cronbach & Meehl, 1955; LeBel, Berger, Campbell, & Loving, 2017), and vetting of methods by advisors with expertise in measurement and quantitative analysis.\n\n\nOpenness to criticism\nThe PSA integrates critical assessment of its policies and research products into its process, requiring extensive review of all projects and annually soliciting external feedback on the organization as a whole."
  },
  {
    "objectID": "news/2022-12-06_2nd-call.html",
    "href": "news/2022-12-06_2nd-call.html",
    "title": "Second Special Call for Studies – Studying Generalizability with Global Samples",
    "section": "",
    "text": "Initial Proposals (Optional) due by February 15, 2023.\nFull Proposals due by May 15, 2023."
  },
  {
    "objectID": "news/2022-12-06_2nd-call.html#deadlines",
    "href": "news/2022-12-06_2nd-call.html#deadlines",
    "title": "Second Special Call for Studies – Studying Generalizability with Global Samples",
    "section": "",
    "text": "Initial Proposals (Optional) due by February 15, 2023.\nFull Proposals due by May 15, 2023."
  },
  {
    "objectID": "news/2022-12-06_2nd-call.html#overview",
    "href": "news/2022-12-06_2nd-call.html#overview",
    "title": "Second Special Call for Studies – Studying Generalizability with Global Samples",
    "section": "Overview",
    "text": "Overview\nThe PSA is a distributed network of researchers from the behavioral sciences across the globe. Our more than 2400 collaborators represent 73 countries from all six populated continents. The mission of the PSA is to accelerate the accumulation of reliable and generalizable evidence in psychological science. This call for studies will select projects that fit within the 5 topic areas, broadly construed, that are prioritized by the JTF. Both members and non-members of the PSA can submit proposals."
  },
  {
    "objectID": "news/2022-12-06_2nd-call.html#jtf-priority-topics",
    "href": "news/2022-12-06_2nd-call.html#jtf-priority-topics",
    "title": "Second Special Call for Studies – Studying Generalizability with Global Samples",
    "section": "JTF Priority Topics",
    "text": "JTF Priority Topics\nTo be eligible for this call, projects must investigate research questions related to one or more of the strategic priorities of the JTF in university and community samples across the globe. Below is a list of those priorities. Each is followed by some example research questions and topics. These are meant to just be examples; they are not an exhaustive list of the research questions that could be encompassed by each priority.\n\nThe dynamics of religious change. Why do religions flourish or lose adherents? What kinds of features of religious organizations drive or repel members? Why and how do people switch religious identities?\nIntellectual humility. Which factors enhance or inhibit intellectual humility? How can we better study the concept of intellectual humility?\nReligious cognition. What is the nature of religious belief and how can it be better measured? What causes religious or spiritual experiences and what are the effects of those experiences? How do individuals develop and revise their religious beliefs?\nThe science of character virtue. In particular, what helps individuals to develop curiosity and love? What are the consequences of those virtues? How do religions and perceptions of supernatural agents affect virtue and morality development?\nHealth, religion, and spirituality. Are there associations between religious/spiritual beliefs, experiences, practices, and identities, and physical and mental health? If so, are there underlying causal mechanisms?"
  },
  {
    "objectID": "news/2022-12-06_2nd-call.html#study-incubation",
    "href": "news/2022-12-06_2nd-call.html#study-incubation",
    "title": "Second Special Call for Studies – Studying Generalizability with Global Samples",
    "section": "Study Incubation",
    "text": "Study Incubation\nUnlike previous PSA calls, this call includes the option of submitting a short initial proposal that will be considered for study incubation. See section below for requirements.\nThe intention of incubation is to support proposing authors in developing a full proposal. This extra step is designed to remove barriers to submission and increase the competitiveness of proposals from researchers who are under-represented in psychological science (broadly defined and self-identified). \nAuthors of all initial proposals will be given written feedback and the opportunity to meet with someone from the grant team to discuss their projects. A subset of these proposals will also be selected for further incubation. Proposing authors of these submissions will be provided additional guidance in the form of meetings, full proposal draft feedback, and ad hoc support.\nShort proposals may be submitted at any point up until February 15, 2023, and will be evaluated on a rolling basis for feedback and support needs."
  },
  {
    "objectID": "news/2022-12-06_2nd-call.html#proposal-selection",
    "href": "news/2022-12-06_2nd-call.html#proposal-selection",
    "title": "Second Special Call for Studies – Studying Generalizability with Global Samples",
    "section": "Proposal Selection",
    "text": "Proposal Selection\nAll full proposals, regardless of whether they were a part of study incubation, will have the same requirements and will be given equal consideration during the project selection process.\nPSA projects are selected using a rigorous review process. Researchers submit detailed proposals for consideration. These proposals resemble Stage 1 Registered Reports (e.g., Chambers, 2013), and contain a theoretical introduction and hypothesis, a description of the planned sample and methods, and an analysis plan to test those hypotheses (see below section for requirements).\nThe proposals then undergo several rounds of review, overseen by the PSA’s Study Selection Committee (SSC). First, each proposal is screened for feasibility given the PSA’s current capacity and resources (Initial feasibility and quality review). For instance, a proposal that requires dozens of collection sites with fMRI machines is likely to be rejected based on infeasibility. Simultaneously, the SSC screens out submissions deemed low quality. Proposals that pass this screening are then sent out for peer review (Reviewer identification & review submission). Each proposal is reviewed by 5-10 reviewers, consisting of both PSA members and external experts. These reviewers are identified based on their ethical, methodological, and/or theoretical expertise related to a given proposal. All submissions are also rated quantitatively by members of the PSA network (Network rating). The SSC then synthesizes the reviewer and network feedback to select projects for the PSA to pursue (Study selection decision). See Evaluation Criteria section for more details and anticipated timeline."
  },
  {
    "objectID": "news/2022-12-06_2nd-call.html#funding-and-personnel-support-for-studies-resulting-from-this-call",
    "href": "news/2022-12-06_2nd-call.html#funding-and-personnel-support-for-studies-resulting-from-this-call",
    "title": "Second Special Call for Studies – Studying Generalizability with Global Samples",
    "section": "Funding and Personnel Support for Studies Resulting from this Call",
    "text": "Funding and Personnel Support for Studies Resulting from this Call\nProjects selected through this special call will be advertised to members of the PSA network in collaboration with the proposing authors. Each study will be supported by $40,000 of direct funding for data collection. Specifically, these funds will be distributed to network data collection teams, primarily for the purposes of compensating participants from their local communities.\nThe proposing author teams will also be collectively supported by 3 full-time scientific staff members (a Research Coordinator [Erin Seivers], a Postdoctoral Researcher [Dr. Priya Silverstein], and a Research Scientist [Dr. Kathleen Schmidt]), an additional ⅓ time senior staff member (Dr. Christopher R. Chartier), a ½ time staff member equivalent team of undergraduate research assistants, several members of PSA committees (at their discretion), and members of the network at large (at their discretion)."
  },
  {
    "objectID": "news/2022-12-06_2nd-call.html#submission-requirements",
    "href": "news/2022-12-06_2nd-call.html#submission-requirements",
    "title": "Second Special Call for Studies – Studying Generalizability with Global Samples",
    "section": "Submission Requirements",
    "text": "Submission Requirements\n\nInitial Proposals (Optional – these will be considered for incubation)\nInitial proposals should be 500-1000 words in length and include rationale for the project and an overview of the research design. As part of the submission form, proposing authors will provide details about their research including type, investigation category, relevant JTF priority/ies, and subfield. They will also be asked to describe how the additional support provided by the study incubation process would help them overcome barriers to submitting a full proposal or otherwise benefit their submission.\n\n\nFull Proposals (Required)\nThe following manuscript components are required for all full proposals:\n\nCover Page, including the title of the study, date of the latest draft, and keywords\nAbstract of up to 150 words\nMain body submission text of up to 5,000 words\nA version of the submission with a cover page included\nA masked version of the submission without the cover page\nReferences\nSupplementary materials\n\nThe following guidelines are intended to assist you in the preparation of your proposal submission to the PSA. Submissions typically include a description of the key background literature and motivation for the study, hypotheses, study procedures, proposed statistical analysis plan, a statistical power analysis, and pilot data (wherever applicable).\n\nIntroduction\nA review of the relevant literature that motivates the research question and a full description of the study aims and hypotheses. Method\nA full description of proposed sample characteristics, including criteria for data inclusion and exclusion (e.g., outlier extraction). Procedures for objectively defining exclusion criteria caused by technical errors or for any other reasons must be specified, including details of how and under what conditions data would be replaced.\nA description of study procedures in sufficient detail to allow another researcher to repeat the methodology exactly, without requiring further information.\n\n\nAnalysis Plan\nProposed analysis pipeline, including all preprocessing steps, and a precise description of all planned analyses, including appropriate correction for multiple comparisons. Specify all covariates or regressors. Specify analysis decisions that are contingent on the outcome of prior analyses.\nStudies involving frequentist inference must include a statistical power analysis. Estimated effect sizes should be justified with reference to the existing literature or theory. Because publication bias inflates published estimates of effect size, power analysis should be based on the lowest available or meaningful estimate of the effect size.\nIn the case of highly uncertain effect sizes, variable sample size and interim data analysis is permissible but with inspection points stated in advance, appropriate Type I error correction for ‘peeking’ employed, and a final stopping rule for data collection outlined.\nFor studies involving analyses with Bayes factors, the predictions of the theory must be specified so that a Bayes factor can be calculated. Authors should indicate what distribution will be used to represent the predictions of the theory and how its parameters will be specified.\nFull descriptions must be provided of any outcome-neutral criteria that must be met for successful testing of the stated hypotheses. Such quality checks might include the absence of floor or ceiling effects in data distributions, positive controls, or other quality checks that are orthogonal to the experimental hypotheses.\n\n\nSupplemental Materials\nInclude full questionnaires, stimuli, and materials needed to conduct the study. Pilot data can be included to establish proof of concept, effect size estimations, or feasibility of proposed methods. Simulated data and analysis scripts are recommended to provide clarity about the exclusion criteria and analysis plan.\nPlease also describe within the supplemental materials the details of what open research practices will be followed and how. This section should include information about plans for data sharing, analysis code sharing, pre-print use, and Registered Report manuscript submission and/or pre-registration. Other practices which are common in PSA studies are open materials, use of open source tools, and open research workflows. \nThese guidelines were adapted from https://osf.io/pukzy."
  },
  {
    "objectID": "news/2022-12-06_2nd-call.html#evaluation-criteria",
    "href": "news/2022-12-06_2nd-call.html#evaluation-criteria",
    "title": "Second Special Call for Studies – Studying Generalizability with Global Samples",
    "section": "Evaluation Criteria",
    "text": "Evaluation Criteria\nWe anticipate that three studies will be selected and implemented through this call.\nAppropriateness for this special call for studies is one of the key criteria for evaluation. Your full proposal should clearly state how your project aligns with the goals of the call and discuss why your research topic would specifically benefit from global data collection (e.g., theoretical reasons to predict global variation).\nUpon submission of your full proposal, you will be asked to provide details about your project to categorize the submission and help the study selection committee assess its fit and feasibility. These items are listed below (see also the submission form link).\n\nWhat type of research are you proposing?\nWhat category of investigation is your project?\nTo which JTF strategic priority does your research relate? Select all that apply.\nWhat area of psychology best describes the research?\nTarget number of data collection sites\nTarget number of participants per data collection sites\nDoes your project require specialized equipment (e.g., eye-tracking, EEG) or proprietary experimental software (e.g., E-Prime) to be used at the data collection sites?\n\nIf yes: Please explain and justify the use of specialized equipment or proprietary software in your research. Can you provide the collection sites with these resources? Do you only need a minority of sites to participate who already have these resources?\n\nCan experimental materials and analysis scripts for your project be easily shared and made publicly available?\n\nIf no: Please explain and justify why your materials or analysis scripts cannot be publicly shared.\n\nDoes your project require “hard-to reach” samples (e.g., children, traditionally marginalized group members, clinical populations, etc.)?\n\nIf yes: Please explain and justify your use of “hard to reach” samples in your research. Do you only need a minority of sites to participate who already have access to these populations? If not, how will they recruit participants? Does research with this population involve additional ethical considerations?\n\nDoes the study expose participants to more risk than they would encounter in everyday life?\n\nIf yes: Please explain and justify the potential risk to individuals who participate in your proposed study.\n\n\nIn evaluating submissions for this special call for studies, we will prioritize projects whose designs are most well suited for promoting generalizability. In particular, we will prioritize studies that seek global samples (as opposed to studies that wish to sample from one or a few countries), studies with very high statistical power, and studies that are more strongly grounded in previous research (such as replication and generalization studies). All of these criteria are intended to maximize our chances of producing generalizable insights on phenomena-of-interest.\nIn addition, we will evaluate proposals for this special call together so that we can ensure variation across the projects. In particular, we will strive to select a package of studies that, collectively, represent a range of JTF priorities, study designs (e.g., experimental vs. correlational), and researcher backgrounds (e.g., research specialty, researcher location, etc.). This way, we will avoid overrepresenting a given topic, type of research, or type of researcher in this initiative."
  },
  {
    "objectID": "news/2022-12-06_2nd-call.html#timeline",
    "href": "news/2022-12-06_2nd-call.html#timeline",
    "title": "Second Special Call for Studies – Studying Generalizability with Global Samples",
    "section": "Timeline",
    "text": "Timeline\n\nShort Proposal (optional – to be considered for incubation) latest deadline: February 15, 2023\nShort Proposal feedback and incubation decision: March 1, 2023 (latest date).\nFull Proposal deadline: May 15, 2023.\nInitial feasibility and quality review: May 16 – May 22, 2023.\nReviewer selection: May 22 – May 29, 2023.\nNetwork rating solicitation: May 29, 2023.\nReview submission deadline: June 12, 2023.\nNetwork rating deadline: June 12, 2023.\nStudy selection decision: June 26, 2023.\n\nPossible submission outcomes include “desk rejection” upon initial review, rejection upon full review, provisional acceptance, or an invitation to revise and resubmit.\nFollowing a successful period of needs assessment, preparation, personnel identification, lab recruitment, and pre-registration, provisionally selected studies will commence data collection in late 2023 and end data collection in late 2024.\nPlease use this form to submit your optional initial proposal.\nPlease use this form to submit your required full proposal.\nFor pre-submission inquiries, please email Kathleen Schmidt at kathleenschmidt1@gmail.com or Chris Chartier at cchartie@ashland.edu. They are happy to meet with proposing authors and/or answer questions about what is likely to make for a strong submission."
  },
  {
    "objectID": "funding.html",
    "href": "funding.html",
    "title": "Funding",
    "section": "",
    "text": "Our work has been generously supported by the John Templeton Foundation, the Einstein Foundation, the Leibniz Institute for Psychology, individual donations, and the volunteer efforts of thousands of researchers around the world. With this financial support, we have been able to: - Provide data collection grants for underresourced labs - Collect diverse and representative participant samples - Hire personnel and offer internships - Organize events, like the Big Team Science Conference.\nThe PSA is currently fiscally hosted by the Open Collective Foundation, a registered 501(c)(3) organization. This allows us to accept and manage our finances in a completely transparent and decentralized manner. Records of our expenses and spending summaries are available here.\nIf you are interested in supporting the PSA, you can make [tax-exempt] donations here."
  },
  {
    "objectID": "conf-previous.html",
    "href": "conf-previous.html",
    "title": "Previous Conferences",
    "section": "",
    "text": "In 2020, the PSA created the first conference focused on big team science. In 2020 and 2021, this conference was called PSA-CON and largely focused on projects conducted by members of the PSA.\nBy 2022, it was clear that big team science had proliferated far beyond our community. Thus, we did what we do best: collaborated! Working with the ManyBabies and ManyPrimates consortia, we re-focused the conference on all things big team science and gave it a new name: the Big Team Science Conference (BTS-CON). The inaugural 2022 BTS-CON had over 450 registrants and 50 sessions. With continued support, we hope that this conference will continue to be an inaugural event where people can come together to discuss the challenges, benefits, successes, and future directions of big team science.\nInterested in attending the next BTS-CON? Check out our registration page (link)!"
  },
  {
    "objectID": "submit.html",
    "href": "submit.html",
    "title": "How to Submit",
    "section": "",
    "text": "Research projects completed by the PSA are typically selected from a pool of masked protocols submitted in response to an open call for proposals.\nOur most recent call for proposals, Second Special Call for Studies – Studying Generalizability with Global Samples, was released in December 2022 with a deadline of May 15, 2023.\n\n\nThe PSA occasionally releases general calls for studies from all areas of psychology. Proposed projects may be confirmatory or exploratory, test a novel research question or propose a replication, or explore the validity of measures or stimuli. When project proposals are submitted for consideration, authors are asked to explicitly address feasibility, implementation, and ethics concerns. Non-members can submit proposals, but must join the PSA if the project is selected.\nPSA projects are selected using a rigorous review process. Researchers submit detailed proposals for consideration. These proposals resemble Stage 1 Registered Reports (e.g., Chambers, 2013), and contain a theoretical introduction and hypothesis, a description of the planned sample and methods, and an analysis plan to test those hypotheses.\nThe proposals then undergo several rounds of review, overseen by the PSA’s Study Selection Committee (SSC). First, each proposal is screened for feasibility given the PSA’s current capacity and resources. Simultaneously, the SSC screens out submissions deemed low quality. Proposals that pass this screening are then sent out for peer review. Each proposal is reviewed by 5-10 reviewers, consisting of both PSA members and external experts. These reviewers are identified based on their ethical, methodological, and/or theoretical expertise related to a given proposal. All submissions are also rated quantitatively by members of the PSA network. The SSC then synthesizes the reviewer and network feedback to select projects for the PSA to pursue.\n\n\n\nSpecial calls for studies have specific requirements in addition to those of general calls. These may include stipulations about the research topic, design, or population of interest. See the Second Special Call for Studies – Studying Generalizability with Global Samples for example. Any differences from the standard study selection procedure summarized above are detailed in the call."
  },
  {
    "objectID": "submit.html#general-calls",
    "href": "submit.html#general-calls",
    "title": "How to Submit",
    "section": "",
    "text": "The PSA occasionally releases general calls for studies from all areas of psychology. Proposed projects may be confirmatory or exploratory, test a novel research question or propose a replication, or explore the validity of measures or stimuli. When project proposals are submitted for consideration, authors are asked to explicitly address feasibility, implementation, and ethics concerns. Non-members can submit proposals, but must join the PSA if the project is selected.\nPSA projects are selected using a rigorous review process. Researchers submit detailed proposals for consideration. These proposals resemble Stage 1 Registered Reports (e.g., Chambers, 2013), and contain a theoretical introduction and hypothesis, a description of the planned sample and methods, and an analysis plan to test those hypotheses.\nThe proposals then undergo several rounds of review, overseen by the PSA’s Study Selection Committee (SSC). First, each proposal is screened for feasibility given the PSA’s current capacity and resources. Simultaneously, the SSC screens out submissions deemed low quality. Proposals that pass this screening are then sent out for peer review. Each proposal is reviewed by 5-10 reviewers, consisting of both PSA members and external experts. These reviewers are identified based on their ethical, methodological, and/or theoretical expertise related to a given proposal. All submissions are also rated quantitatively by members of the PSA network. The SSC then synthesizes the reviewer and network feedback to select projects for the PSA to pursue."
  },
  {
    "objectID": "submit.html#special-calls",
    "href": "submit.html#special-calls",
    "title": "How to Submit",
    "section": "",
    "text": "Special calls for studies have specific requirements in addition to those of general calls. These may include stipulations about the research topic, design, or population of interest. See the Second Special Call for Studies – Studying Generalizability with Global Samples for example. Any differences from the standard study selection procedure summarized above are detailed in the call."
  }
]